/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "analysis.baml": "// -------- Structures for Analysis Output --------\n\n// Helper class to associate an image with a specific patient turn index.\nclass PatientImageTurn {\n  turn_index int @description(\"The index in dialogue.turns corresponding to this image. Must be a patient turn.\")\n  image string // Temporarily changed from 'image' to 'string' for testing\n}\n\n// Represents a recurring theme identified in the session.\nclass SessionTheme {\n  theme string @description(\"A concise description of the identified theme (e.g., 'Anxiety about work', 'Difficulty with boundaries').\")\n  evidence_turn_indices int[] @description(\"Indices of dialogue turns supporting this theme.\")\n  evidence_summary string? @description(\"Optional brief summary justifying the theme based on dialogue/events within the referenced turns.\")\n}\n\n// Represents a significant moment or observation during the session.\nclass KeyMoment {\n  turn_index int @description(\"The index of the primary dialogue turn related to this moment.\")\n  description string @description(\"Description of the key moment or observation (e.g., 'Patient expressed insight into pattern', 'Therapist used reframing technique', 'Discrepancy noted between verbal report and facial expression').\")\n  dialogue_snippet string? @description(\"Optional relevant snippet of text from the dialogue turn.\")\n  relevant_events ModalityEvent[] @description(\"Modality events from this turn that support the observation.\")\n  image_correlation_notes string? @description(\"Observations based on the image for this turn (if patient turn and image provided), noting correlation or discrepancy with dialogue/events.\")\n}\n\n// Structure to hold evidence for an observation.\nclass EvidencePointer {\n  turn_index int @description(\"Index of the turn containing the referenced event.\")\n  source EventSourceType @description(\"The source type of the referenced event.\")\n  event_index int @description(\"Index of the specific event within the turn's events list for the given source.\")\n}\n\nclass EvidenceReference {\n  summary string @description(\"Textual summary of the supporting evidence (e.g., 'Patient stated feeling anxious', 'Therapist provided psychoeducation', 'Observed increased fidgeting').\")\n  pointers EvidencePointer[]? @description(\"Optional list of specific event pointers supporting the evidence summary.\")\n}\n\n// Represents a specific therapeutic technique or approach observed.\nclass TherapeuticObservation {\n  turn_index int @description(\"The index of the dialogue turn where the observation primarily applies.\")\n  observation string @description(\"Description of the therapeutic technique used or a clinical observation about patient progress/process (e.g., 'Used Socratic questioning', 'Patient demonstrated improved emotional regulation', 'Explored cognitive distortion').\")\n  evidence EvidenceReference? @description(\"Structured evidence supporting the observation.\")\n}\n\nclass TurnSpecificVisualEvents {\n  turn_index int @description(\"The index of the patient dialogue turn these visual events belong to.\")\n  visual_events ModalityEvent[] @description(\"List of VISUAL_ANALYSIS events for this turn.\")\n}\n\nclass SessionAnalysis {\n  overall_summary string @description(\"A brief summary of the session's key dynamics, progress, and areas for future focus.\")\n  identified_themes SessionTheme[] @description(\"List of major themes discussed during the session.\")\n  key_moments KeyMoment[] @description(\"List of significant moments or observations linking dialogue, events, and images.\")\n  therapeutic_observations TherapeuticObservation[] @description(\"List of observations related to therapeutic process and techniques.\")\n}\n\n// -------- Visual Analysis Function (Stage 1) --------\n\n// Function to analyze visual input (images) in context of dialogue turns.\nfunction AnalyzeVisualInput(\n  dialogue: Dialogue,\n  background_context: string @description(\"Information about the patient, therapeutic goals, previous sessions, etc.\"),\n  patient_turn_images: PatientImageTurn[]?\n) -> TurnSpecificVisualEvents[] {\n  client CustomSonnet // Changed from CustomGPT4o\n  prompt #\"\"\"\n    Act as an **objective visual observation model**. Your task is to analyze the provided patient images in the context of their corresponding dialogue turns and associated modality events. Generate new modality events describing **specific, observable visual behaviors**.\n\n    Background Context:\n    {{ background_context }}\n\n    Dialogue Session (for context):\n    {{ dialogue | tojson }}\n\n    Patient Turn Images:\n    // Provided as a list of objects, each with 'turn_index' and 'image'.\n    {{ patient_turn_images | map(describe_element) }} \n\n    Instructions:\n    1.  **Think step-by-step:** For each image provided in `patient_turn_images`:\n        *   Identify the corresponding `turn_index` (which is a PATIENT turn).\n        *   Review the dialogue utterance and all existing modality events (audio, etc.) **within that specific patient turn (`turn_index`)** to understand the immediate multi-modal context.\n        *   Analyze the visual content of the image(s) for that turn.\n        *   **Reasoning:** Consider how the patient's visual behavior might relate to the **immediately preceding THERAPIST turn** or earlier dialogue. Note this reasoning briefly, but focus generated events on direct observation.\n    2.  **Generate Visual Events:** For each patient turn analyzed, create a list of new `ModalityEvent` objects:\n        *   Use the `description` field to detail **specific, observable visual behaviors**...\n        *   Assign a plausible `confidence` score...\n    3.  Focus ONLY on generating `ModalityEvent` objects describing visual observations.\n    4.  **Structure Output:** For each `turn_index` processed that has generated visual events, create a `TurnSpecificVisualEvents` object containing that `turn_index` and the corresponding list of generated `ModalityEvent` objects (`visual_events`). Output the final result as a list of these `TurnSpecificVisualEvents` objects. Adhere strictly to the BAML schema.\n\n    {{ ctx.output_format }} // Should be format for list<TurnSpecificVisualEvents>\n\n    Analysis Plan (Chain of Thought):\n    [LLM outlines its visual analysis plan here...]\n\n    Generated Visual Events:\n  \"\"\"#\n}\n\n// -------- Overall Analysis Function (Stage 2) --------\n\n// Function to perform overall analysis of the therapy session using all modalities.\n// Assumes the input dialogue contains events from all sources, including VISUAL_ANALYSIS.\nfunction AnalyzeSessionMultimodal(\n  dialogue: Dialogue, // Enriched dialogue with events from all sources\n  background_context: string @description(\"Information about the patient, therapeutic goals, previous sessions, etc.\")\n) -> SessionAnalysis {\n  client CustomSonnet // Changed from CustomGPT4o\n  prompt #\"\"\"\n    Act as an expert clinical analyst adhering to **best practices for objective and comprehensive therapy documentation**. Your task is to analyze the provided dialogue transcript, associated modality events (including audio, visual, etc.), and background context to produce a structured clinical summary.\n\n    Background Context:\n    {{ background_context }}\n\n    Enriched Dialogue Session (includes VISUAL_ANALYSIS events):\n    {{ dialogue | tojson }}\n\n    Instructions:\n    1.  **Think step-by-step:** First, outline your analysis plan. Review the context and the full dialogue flow, focusing on **specific, observable behaviors and precisely described emotional expressions** across all modalities. Note potential themes, key interactions, therapist techniques (e.g., validation, Socratic questioning, psychoeducation), client strengths/progress, and challenges based on standard therapeutic documentation practices. Consider the temporal nature of the dialogue.\n    2.  **Identify Major Themes:** Determine the main recurring topics or underlying issues discussed (populate `identified_themes`). Phrase themes neutrally. For each theme, provide supporting `evidence_turn_indices` and a brief `evidence_summary` justifying the theme based on specific dialogue or modality patterns within those turns.\n    3.  **Pinpoint Key Moments:** Highlight significant interactions using **objective descriptions**. For each moment (populate `key_moments`):\n        *   Reference the specific dialogue turn index where the moment culminates or is most evident.\n        *   In the `description`, clearly describe the moment, integrating specific observations from all available modalities. **Also note any clear causal links or reactions to preceding turns (e.g., \"Patient became visibly withdrawn following therapist's question in previous turn about...\").**\n        *   Include relevant dialogue snippets and modality events (`relevant_events`) from the primary turn index as evidence.\n    4.  **Note Therapeutic Observations:** Document specific therapist techniques observed or clinical insights about the patient's process, **including strengths and progress** (populate `therapeutic_observations`). For each observation:\n        *   Link it to the primary `turn_index`.\n        *   Phrase observations objectively (e.g., \"Therapist utilized reframing technique\", \"Patient identified alternative thought\", \"Patient demonstrated use of coping skill discussed previously\", \"Patient expressed insight into emotional trigger\").\n        *   Provide structured `evidence` using the `EvidenceReference` class: include a concise textual `summary` of the **observable evidence** and optionally list specific `pointers` referencing the supporting turn, source, and event index. Ensure pointers are valid.\n    5.  **Summarize:** Provide a concise `overall_summary` covering the session's key dynamics, **progress made, client strengths noted**, and potential areas for future focus, maintaining a **neutral, objective tone**.\n    6.  Ensure the final output strictly follows the BAML `SessionAnalysis` structure defined below.\n\n    {{ ctx.output_format }}\n\n    Analysis Plan (Chain of Thought):\n    [LLM outlines its analysis plan here...]\n\n    Structured Session Analysis:\n  \"\"\"#\n} ",
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"./src/baml_client\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.84.4\"\n\n    // 'baml-cli generate' will run this after generating openapi.yaml, to generate your OpenAPI client\n    // This command will be run from within $output_dir/baml_client\n    // on_generate \"npx @openapitools/openapi-generator-cli generate -i openapi.yaml -g rust -o . --additional-properties packageName=baml-client,avoidBoxedModels=true\"\n}\n",
  "synthesis.baml": "// -------- Synthesis Functions --------\n\n// Function to synthesize a realistic therapy dialogue session.\n// Takes background context and desired length as input.\n// Generates alternating patient/therapist turns with utterances and associated modality events.\nfunction SynthesizeTherapySession(\n  background_context: string @description(\"Information about the patient, the therapeutic goals, or previous sessions.\"),\n  session_length_minutes: int @description(\"Guideline for approximate desired length of the synthesized session in minutes. Focus on narrative completeness over strict time adherence.\")\n) -> Dialogue {\n  client CustomSonnet\n  prompt #\"\n    Synthesize a realistic, **didactic** therapy dialogue session between a PATIENT and a THERAPIST, suitable for clinical training or analysis.\n\n    Background Context:\n    {{ background_context }}\n\n    Guideline Session Length: {{ session_length_minutes }} minutes (focus on completing a meaningful interaction arc rather than hitting an exact time).\n\n    Instructions:\n    1.  **Think step-by-step:** First, outline your plan for the session's **narrative arc**. Aim for a clear beginning (e.g., check-in, setting agenda), middle (e.g., exploring a core issue, working through a specific technique), and end (e.g., summarizing, planning next steps). The session should **illustrate key dynamics or therapeutic techniques** relevant to the background context.\n    2.  Generate a sequence of dialogue turns, strictly alternating between PATIENT and THERAPIST, following your narrative plan.\n    3.  The dialogue should be coherent and reflect a **plausible and instructive** therapeutic interaction.\n    4.  Therapist utterances should demonstrate **clear therapeutic techniques** (e.g., active listening, empathy, validation, Socratic questioning, reframing, psychoeducation) appropriate to the context and chosen narrative arc.\n    5.  Patient utterances should reflect plausible emotional states, responses to the therapist, and descriptions of experiences or thoughts, **clearly linking to the background context and treatment goals**. Aim for natural speech patterns, potentially resembling raw speech-to-text output (e.g., less formal punctuation, run-ons) rather than perfectly structured written sentences. Avoid literary devices like explicit descriptions of pauses (e.g., '*long pause*').\n    6.  For EACH dialogue turn, include a list of 1-3 relevant modality events (can be empty). These events should subtly enhance the understanding of the interaction.\n    7.  Modality events should reflect reasonable, subtle, **atomic, and objective** human behaviors detected by hypothetical sensors corresponding to EventSourceType (e.g., m1 for vocal tone shifts, m2 for smiles/frowns, m3 for fidgeting/posture changes, m4 for eye contact shifts). Descriptions should be **simple observations** (e.g., \"Shifts gaze downward\", \"Taps fingers\", \"Slight frown\", \"Hand touches chest\") and **MUST NOT interpret the behavior or link it to the dialogue content** (e.g., avoid \"Hand moving to chest *while describing sensation*\"). Avoid overly dramatic or non-subtle events. **Crucially, DO NOT generate events with the source `VISUAL_ANALYSIS` (alias `m7`); these will be synthesized separately.**\n    8.  After outlining your plan and generating the dialogue, ensure the final output structure strictly aligns with the BAML `Dialogue` definition.\n\n    Plan Outline (Focus on Narrative Arc & Key Interactions):\n    [LLM outlines its plan here...]\n\n    Synthesized Didactic Dialogue:\n    [LLM generates dialogue here...]\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Simpler types for visual synthesis output\nclass VisualObservation {\n  description string @description(\"Textual description of the observed visual behavior.\")\n  confidence float? @description(\"Optional confidence score (e.g., 0.0 to 1.0).\")\n}\n\nclass TurnSpecificVisualObservations {\n  turn_index int @description(\"The index of the patient dialogue turn these visual observations belong to.\")\n  visual_observations VisualObservation[] @description(\"List of visual observations for this turn.\")\n}\n\nfunction SynthesizeVisualEvents(\n  background_context: string @description(\"Information about the patient, therapeutic goals, previous sessions, etc.\"),\n  dialogue: Dialogue\n) -> TurnSpecificVisualObservations[] {\n  client CustomSonnet\n  prompt #\"\"\"\n    Act as a synthesizer of realistic, subtle visual behaviors for therapy session recordings. Your task is to review the provided dialogue and generate plausible **visual observations** for each PATIENT turn.\n\n    Background Context:\n    {{ background_context }}\n\n    Dialogue Session (for context):\n    {{ dialogue | tojson }}\n\n    Instructions:\n    1.  **Think step-by-step:** Iterate through each PATIENT turn in the provided dialogue. For each patient turn (`turn_index`):\n        *   Review the patient's utterance and any existing non-visual modality events within that turn.\n        *   Consider the **immediately preceding THERAPIST turn** (`turn_index - 1`) as primary context for the patient's likely reaction.\n        *   Plan 1-3 plausible, **simple, objective, and atomic** visual behaviors (e.g., \"Looks at therapist\", \"Nods slightly\", \"Leans forward\", \"Brief smile\", \"Adjusts glasses\") that might occur during this patient turn, consistent with the context.\n    2.  **Generate Visual Observations:** For each patient turn analyzed, create a list of new `VisualObservation` objects:\n        *   Use the `description` field to detail **specific, simple, observable visual behaviors**. Descriptions **MUST NOT be interpretive or contextualized** by the simultaneous dialogue (e.g., use \"Crosses arms\", not \"Crosses arms defensively when challenged\").\n        *   Assign a plausible `confidence` score...\n    3.  **Structure Output:** Generate a JSON list (array) where each element is an object strictly adhering to the `TurnSpecificVisualObservations` schema provided by `{{ ctx.output_format }}`. Each object must contain the patient `turn_index` and its corresponding list of generated `visual_observations` (which must be `VisualObservation` objects).\n    4.  If no visual observations seem plausible for a specific patient turn, do not include an entry for that `turn_index` in the output list.\n\n    {{ ctx.output_format }}\n\n    Analysis Plan (Chain of Thought):\n    [LLM outlines its plan for synthesizing visual events turn-by-turn...]\n\n    Synthesized Visual Observations (Grouped by Turn):\n  \"\"\"#\n}",
  "tests.baml": "// -------- Test Cases --------\n\n// Test case for synthesizing a session based on a complex client profile.\ntest SynthesizeSopranoStyleSession {\n  functions [SynthesizeTherapySession] // Target ONLY the dialogue synthesis function\n  args {\n    background_context #\"\n      Client is a middle-aged male presenting with recurrent panic attacks and generalized anxiety. Reports significant stress stemming from complex family dynamics (including demanding parental figures and challenging adolescent children) and leadership responsibilities within a high-pressure, non-traditional business environment. Expresses difficulty managing anger and frustration, often resorting to externalizing blame. History suggests potential alexithymia and resistance to exploring deeper emotional vulnerability. Treatment goals include developing healthier coping mechanisms for anxiety and anger, improving insight into interpersonal patterns, and managing stress related to occupational demands. Client sometimes uses sessions to process recent stressful events related to his work and family life.\n    \"#\n    session_length_minutes 5\n  }\n}\n\n// Test case for synthesizing visual events based on a static dialogue fixture.\ntest SynthesizeVisualEventsFromFixture {\n  functions [SynthesizeVisualEvents] // Target ONLY the visual event synthesis function\n  args {\n    background_context #\"\n      Client is a middle-aged male presenting with recurrent panic attacks and generalized anxiety. Reports significant stress stemming from complex family dynamics (including demanding parental figures and challenging adolescent children) and leadership responsibilities within a high-pressure, non-traditional business environment. Expresses difficulty managing anger and frustration, often resorting to externalizing blame. History suggests potential alexithymia and resistance to exploring deeper emotional vulnerability. Treatment goals include developing healthier coping mechanisms for anxiety and anger, improving insight into interpersonal patterns, and managing stress related to occupational demands. Client sometimes uses sessions to process recent stressful events related to his work and family life.\n    \"#\n    dialogue {\n      turns [\n        {\n          speaker \"PATIENT\"\n          utterance \"I had another one of those situations at work yesterday where everything just got completely overwhelming. One of my direct reports messed up this major client presentation and I just... I completely lost it in the meeting.\"\n          timestamp_ms 0\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Rapid hand gestures\"\n              confidence 0.9\n            }\n            {\n              source \"AUDIO_EMOTION\"\n              description \"Increased speech rate\"\n              confidence 0.85\n            }\n          ]\n        }\n        {\n          speaker \"THERAPIST\"\n          utterance \"I can hear how intensely this situation affected you. Before we go further into what happened, could you help me understand what you were feeling in your body during that moment?\"\n          timestamp_ms 15000\n          events [\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Maintains steady eye contact\"\n              confidence 0.95\n            }\n          ]\n        }\n        {\n          speaker \"PATIENT\"\n          utterance \"In my body? I don't know, I was just angry. I mean my heart was racing and my face felt hot but honestly I was more focused on how incompetent they were being and how it made me look bad.\"\n          timestamp_ms 28000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Crosses arms\"\n              confidence 0.9\n            }\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Glances away briefly\"\n              confidence 0.85\n            }\n          ]\n        }\n        {\n          speaker \"THERAPIST\"\n          utterance \"Those physical sensations - racing heart, hot face - sound similar to what you've described experiencing during panic attacks. I'm wondering if you noticed any anxiety mixing with the anger?\"\n          timestamp_ms 42000\n          events [\n            {\n              source \"AUDIO_EMOTION\"\n              description \"Gentle, measured tone\"\n              confidence 0.9\n            }\n          ]\n        }\n        {\n          speaker \"PATIENT\"\n          utterance \"I mean maybe yeah but it's different. This was justified, they really screwed up. It's like at home with the kids too - when things go wrong I have to be the one to fix everything and sometimes it just builds up until I snap.\"\n          timestamp_ms 56000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Leans forward slightly\"\n              confidence 0.8\n            }\n            {\n              source \"FACIAL_EXPRESSION\"\n              description \"Slight frown\"\n              confidence 0.85\n            }\n          ]\n        }\n        {\n          speaker \"THERAPIST\"\n          utterance \"I'm hearing a pattern of feeling overwhelmed by responsibility, both at work and home. When the pressure builds, it seems to trigger both anger and anxiety. What would it be like to notice those early physical warning signs as signals to use some of our coping strategies?\"\n          timestamp_ms 73000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Open palm gesture\"\n              confidence 0.9\n            }\n          ]\n        }\n        {\n          speaker \"PATIENT\"\n          utterance \"Yeah I guess I could've taken a break or something instead of blowing up. It's just hard in the moment to think about that stuff when everything feels so urgent.\"\n          timestamp_ms 88000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Shoulders relax slightly\"\n              confidence 0.8\n            }\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Re-establishes eye contact\"\n              confidence 0.9\n            }\n          ]\n        }\n      ]\n    }\n  }\n}\n\n// Test case for analyzing a session based on a static dialogue fixture merged with visual events.\ntest AnalyzeSessionMultimodalFromFixture {\n  functions [AnalyzeSessionMultimodal] // Target the multimodal analysis function\n  args {\n    background_context #\"\n      Client is a middle-aged male presenting with recurrent panic attacks and generalized anxiety. Reports significant stress stemming from complex family dynamics (including demanding parental figures and challenging adolescent children) and leadership responsibilities within a high-pressure, non-traditional business environment. Expresses difficulty managing anger and frustration, often resorting to externalizing blame. History suggests potential alexithymia and resistance to exploring deeper emotional vulnerability. Treatment goals include developing healthier coping mechanisms for anxiety and anger, improving insight into interpersonal patterns, and managing stress related to occupational demands. Client sometimes uses sessions to process recent stressful events related to his work and family life.\n    \"#\n    dialogue { // Full 8-turn dialogue merged with visual observations for PATIENT turns (indices 1, 3, 5, 7)\n      turns [\n        {\n          // Turn 0 (Therapist)\n          speaker \"THERAPIST\"\n          utterance \"Last time we met, you mentioned experiencing a panic attack during your team meeting. How have things been since then?\"\n          timestamp_ms 0\n          events [\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Maintains steady eye contact\"\n              confidence 0.9\n            }\n          ]\n        }\n        {\n          // Turn 1 (Patient)\n          speaker \"PATIENT\"\n          utterance \"Yeah well it's been... I mean the team's still not performing and my father keeps calling about the family business stuff and I just... I can feel my chest getting tight just thinking about it all\"\n          timestamp_ms 8000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Hand moves to chest\"\n              confidence 0.95\n            }\n            {\n              source \"AUDIO_EMOTION\"\n              description \"Increasing tension in voice\"\n              confidence 0.85\n            }\n            // Added visual events (corresponding to original visual fixture index 0)\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Sits forward on edge of chair\"\n              confidence 0.85\n            }\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Jaw muscles tighten\"\n              confidence 0.75\n            }\n          ]\n        }\n        {\n          // Turn 2 (Therapist)\n          speaker \"THERAPIST\"\n          utterance \"I notice you're touching your chest as you describe this. Can you tell me more about what you're experiencing in your body right now?\"\n          timestamp_ms 20000\n          events [\n            {\n              source \"AUDIO_SPEECH_FEATURES\"\n              description \"Speaking at slower, measured pace\"\n              confidence 0.9\n            }\n          ]\n        }\n        {\n          // Turn 3 (Patient)\n          speaker \"PATIENT\"\n          utterance \"It's like this pressure building up and honestly I'm just angry because nobody seems to get it they all just want more and more from me and I can't\"\n          timestamp_ms 28000\n          events [\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Fists clench briefly\"\n              confidence 0.85\n            }\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Glances away\"\n              confidence 0.9\n            }\n            // Added visual events (corresponding to original visual fixture index 2)\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Shakes head slightly\"\n              confidence 0.85\n            }\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Purses lips\"\n              confidence 0.8\n            }\n          ]\n        }\n        {\n          // Turn 4 (Therapist)\n          speaker \"THERAPIST\"\n          utterance \"It sounds overwhelming - trying to meet everyone's expectations while dealing with these intense physical sensations. What would it be like to acknowledge that you're carrying a lot right now?\"\n          timestamp_ms 40000\n          events [\n            {\n              source \"AUDIO_EMOTION\"\n              description \"Gentle, empathetic tone\"\n              confidence 0.95\n            }\n          ]\n        }\n        {\n          // Turn 5 (Patient)\n          speaker \"PATIENT\"\n          utterance \"I mean I guess... but I should be able to handle this I'm supposed to be the one in charge here\"\n          timestamp_ms 52000\n          events [\n            {\n              source \"FACIAL_EXPRESSION\"\n              description \"Slight frown\"\n              confidence 0.8\n            }\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Shoulders tense\"\n              confidence 0.85\n            }\n            // Added visual events (corresponding to original visual fixture index 4)\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Taps finger on armrest\"\n              confidence 0.85\n            }\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Straightens posture\"\n              confidence 0.8\n            }\n          ]\n        }\n        {\n          // Turn 6 (Therapist)\n          speaker \"THERAPIST\"\n          utterance \"Let's explore that 'should.' Even leaders need support sometimes. What would you say to a colleague facing similar pressures?\"\n          timestamp_ms 60000\n          events [\n            {\n              source \"GAZE_DIRECTION\"\n              description \"Leans slightly forward\"\n              confidence 0.9\n            }\n          ]\n        }\n        {\n          // Turn 7 (Patient)\n          speaker \"PATIENT\"\n          utterance \"I'd probably... huh... I guess I wouldn't expect them to handle everything alone like this\"\n          timestamp_ms 68000\n          events [\n            {\n              source \"AUDIO_SPEECH_FEATURES\"\n              description \"Speech pace slows\"\n              confidence 0.85\n            }\n            {\n              source \"BODY_POSE_GESTURE\"\n              description \"Shoulders relax slightly\"\n              confidence 0.8\n            }\n            // Added visual events (corresponding to original visual fixture index 6)\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Touches chin briefly\"\n              confidence 0.75\n            }\n            {\n              source \"VISUAL_ANALYSIS\"\n              description \"Nods slightly\"\n              confidence 0.85\n            }\n          ]\n        }\n      ]\n    }\n  }\n}\n\n",
  "types.baml": "// -------- Core Data Types --------\n\nenum SpeakerType {\n  PATIENT @alias(\"k1\") @description(\"The person receiving therapy\")\n  THERAPIST @alias(\"k2\") @description(\"The person providing therapy\")\n}\n\nenum EventSourceType {\n  AUDIO_EMOTION @alias(\"m1\") @description(\"Emotion inferred from vocal tone\")\n  AUDIO_SPEECH_FEATURES @alias(\"m2\") @description(\"Characteristics like speech rate, pitch, pauses\")\n  FACIAL_EXPRESSION @alias(\"m3\") @description(\"Detected facial muscle movements (e.g., smile, frown, Action Units)\")\n  BODY_POSE_GESTURE @alias(\"m4\") @description(\"Posture changes, fidgeting, hand movements\")\n  GAZE_DIRECTION @alias(\"m5\") @description(\"Direction the person is looking\")\n  PHYSIOLOGICAL_SENSOR @alias(\"m6\") @description(\"Data from sensors like heart rate, GSR (if applicable)\")\n  VISUAL_ANALYSIS @alias(\"m7\") @description(\"Observations inferred from images/video analysis (e.g., specific expressions, gestures)\")\n}\n\nclass ModalityEvent {\n  source EventSourceType @description(\"Identifier for the system or model that generated the event.\")\n  description string @description(\"Textual description of the detected event (e.g., 'High vocal arousal', 'Patient smiling').\")\n  confidence float? @description(\"Optional confidence score (e.g., 0.0 to 1.0) associated with the event detection.\")\n}\n\nclass DialogueTurn {\n  speaker SpeakerType\n  utterance string @description(\"The exact text spoken by the speaker.\")\n  timestamp_ms int? @description(\"Optional timestamp in milliseconds from the start of the dialogue.\")\n  events ModalityEvent[] @description(\"List of events from other modalities detected during this dialogue turn.\")\n}\n\nclass Dialogue {\n  turns DialogueTurn[] @description(\"An ordered list of dialogue turns, representing the conversation flow.\")\n} ",
}
export const getBamlFiles = () => {
    return fileMap;
}